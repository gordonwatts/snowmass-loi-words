{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering\n",
    "\n",
    "We take the example from scikit-learn (see [here](https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py) and run it on these documents.\n",
    "\n",
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 30 # Perform a SVT reduction - improve accuracy\n",
    "n_cluster = 10 # How many clusters to try to divide things into?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import text_file_info, word_vectors\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import _check_stop_list\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text loading and vectorizing\n",
    "\n",
    "Do the regular feature extraction and then reduce the number of components using SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 570 ms, total: 3.11 s\n",
      "Wall time: 8.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_by_area = list(text_file_info())\n",
    "x, vectorizer = word_vectors([f[2] for f in text_by_area])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 4000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 2.09 s, total: 4.48 s\n",
      "Wall time: 592 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_comp = lsa.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=n_cluster, init='k-means++', max_iter=100, n_init=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 1200.94249332955\n",
      "Iteration 1, inertia 777.8203445452102\n",
      "Iteration 2, inertia 756.5539923632904\n",
      "Iteration 3, inertia 750.231698873486\n",
      "Iteration 4, inertia 747.4077183021097\n",
      "Iteration 5, inertia 744.6322204419322\n",
      "Iteration 6, inertia 741.7662429475806\n",
      "Iteration 7, inertia 737.9867602219574\n",
      "Iteration 8, inertia 735.290005522846\n",
      "Iteration 9, inertia 733.7507927791586\n",
      "Iteration 10, inertia 732.2643421957806\n",
      "Iteration 11, inertia 731.1889113185824\n",
      "Iteration 12, inertia 730.7543824959677\n",
      "Iteration 13, inertia 730.1215163108924\n",
      "Iteration 14, inertia 729.7343447492568\n",
      "Iteration 15, inertia 729.5910127482097\n",
      "Iteration 16, inertia 729.5747308910398\n",
      "Converged at iteration 16: strict convergence.\n",
      "CPU times: user 964 ms, sys: 390 ms, total: 1.35 s\n",
      "Wall time: 181 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=10, n_init=1, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "km.fit(x_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump some info about each of the clusters we found - in particular, the important terms as we can use that to elminiate terms that shouldn't be a factor here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: dark cosmic matter gravitational cmb cosmological galaxy ray survey wave\n",
      "Cluster 1: decays belle decay lhcb lepton flavor rare violation qcd meson\n",
      "Cluster 2: neutrino neutrinos usa dune sterile department reactor icecube oscillation nuclear\n",
      "Cluster 3: detectors readout resolution timing silicon scintillator calorimeter pixel sensors mu2e\n",
      "Cluster 4: accelerator laser plasma electron collider accelerators power srf muon bunch\n",
      "Cluster 5: students computing accelerator software community research learning science education simulation\n",
      "Cluster 6: magnet magnets hts superconducting nb3sn conductor dipole rebco cable accelerator\n",
      "Cluster 7: dark matter axion photon quantum detection search detectors cavity cosmic\n",
      "Cluster 8: lattice qcd quantum quark theory parton gluon calculations collisions lhc\n",
      "Cluster 9: higgs lhc boson collider fcc tev colliders production couplings atlas\n"
     ]
    }
   ],
   "source": [
    "def dump_keywords(km, vectorizer, n_clusters):\n",
    "    original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "    order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(n_clusters):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()\n",
    "        \n",
    "dump_keywords(km, vectorizer, n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_df(text_by_area, km):\n",
    "    cluster_list = []\n",
    "    for (f_name, f_area, _), i_cluster in zip(text_by_area, km.labels_):\n",
    "        cluster_list.append({'name': f_name, 'area': f_area, 'cluster': int(i_cluster)})\n",
    "    return pd.DataFrame(cluster_list)\n",
    "clusters = cluster_df(text_by_area, km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNOWMASS21-AF-TOPIC0-001</td>\n",
       "      <td>AF</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SNOWMASS21-AF0-015</td>\n",
       "      <td>AF</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNOWMASS21-AF0_AF0-091</td>\n",
       "      <td>AF</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SNOWMASS21-AF0_AF0-215</td>\n",
       "      <td>AF</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SNOWMASS21-AF0_AF0-229</td>\n",
       "      <td>AF</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>SNOWMASS21-UF0_UF0_Garcia-Sciveres-001</td>\n",
       "      <td>UF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>SNOWMASS21-UF1_UF4-RF4_RF3_ODonnell-007</td>\n",
       "      <td>UF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>SNOWMASS21-UF4_UF3-NF5_NF6-CF1_CF0-IF3_IF0-Com...</td>\n",
       "      <td>UF</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>SNOWMASS21-UF6_UF0-NF10_NF0-RF4_RF0-CF1_CF0-IF...</td>\n",
       "      <td>UF</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>SNOWMASS21-UF6_UF4-NF5_NF0-CF1_CF0_Tim_Sumner-003</td>\n",
       "      <td>UF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1566 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name area  cluster\n",
       "0                              SNOWMASS21-AF-TOPIC0-001   AF        4\n",
       "1                                    SNOWMASS21-AF0-015   AF        4\n",
       "2                                SNOWMASS21-AF0_AF0-091   AF        4\n",
       "3                                SNOWMASS21-AF0_AF0-215   AF        4\n",
       "4                                SNOWMASS21-AF0_AF0-229   AF        4\n",
       "...                                                 ...  ...      ...\n",
       "1561             SNOWMASS21-UF0_UF0_Garcia-Sciveres-001   UF        5\n",
       "1562            SNOWMASS21-UF1_UF4-RF4_RF3_ODonnell-007   UF        2\n",
       "1563  SNOWMASS21-UF4_UF3-NF5_NF6-CF1_CF0-IF3_IF0-Com...   UF        7\n",
       "1564  SNOWMASS21-UF6_UF0-NF10_NF0-RF4_RF0-CF1_CF0-IF...   UF        3\n",
       "1565  SNOWMASS21-UF6_UF4-NF5_NF0-CF1_CF0_Tim_Sumner-003   UF        2\n",
       "\n",
       "[1566 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how did the clustering do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot('area', kind='count', col='cluster', col_wrap=3, data=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper number of clusters\n",
    "\n",
    "To scan for the proper number of clusters we maximize the silhouette score - which is a measure of how inside a datapoint is in each culster vs out far it is from the rest. It ranges from [1,-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_s_score(x_comp, number_of_clusters: int):\n",
    "    print (f'clustering for {number_of_clusters}')\n",
    "    km = KMeans(n_clusters=number_of_clusters, init='k-means++', max_iter=100, n_init=1, verbose=False, random_state=False)\n",
    "    km.fit(x_comp)\n",
    "    return silhouette_score(x_comp, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = [(int(n_c), cluster_s_score(x_comp, int(n_c))) for n_c in np.linspace(2, 100, num=30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = 25\n",
    "km = KMeans(n_clusters=best_n, init='k-means++', max_iter=100, n_init=1, verbose=False, random_state=False)\n",
    "km.fit(x_comp)\n",
    "dump_keywords(km, vectorizer, best_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clusters = cluster_df(text_by_area, km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot('area', kind='count', col='cluster', col_wrap=3, data=best_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
